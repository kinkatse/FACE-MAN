<h1>Welcome to FACE-MAN wiki!</h1>

<img align="center" src="https://media.discordapp.net/attachments/597985513701376013/882376143607582760/f75decf6732bb1f2e8bfd3a13afe88fe.png" width=350px>
<br/>

<img align="left" src="https://media.discordapp.net/attachments/597985513701376013/870506369223102514/FACE-MAN_Logo_1.png?width=670&height=670" width=100px>
<br/>

<h3>Background</h3>

<a href="https://kinkatse.github.io/FACE-MAN/">FACE-MAN</a> is a face recognition app that checks for two key movements, a person’s open mouth and a person’s closed eyes. The app will recognize which of the two specific facial actions you take and display an animation for when your mouth is open or eyes are closed. This game would use technologies like MediaDevices, TensorFlow, Javascript, Canvas, Node.js, HTML, CSS. The video stream is a loop of video frames captured through the live feed of your camera. The facial movement detection will use algorithms utilizing TensorFlow's ability to acertain points of interest on the face and react to any large movements of the mouth or eyes.

<h3>Technologies, Libraries, & APIs</h3>
 
This project will be implemented with the following technologies:
 
MediaDevices is needed to get user’s video data
TensorFlow will be used to observe a user’s facial actions
The P5/Canvas API to render visuals, filter, animations for successful actions
Webpack and Babel to bundle and transpile the source JavaScript code
npm to manage project dependencies
Node.js
HTML
CSS to style
